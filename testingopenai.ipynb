{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660dc1b5-9295-4aa5-947a-2a1bb3278919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e5473-8d51-440c-92c6-013650567e8e",
   "metadata": {},
   "source": [
    "## what is openai?\n",
    "### The OpenAI API provides a simple interface to state-of-the-art AI models for natural language processing, image generation, semantic search, and speech recognition. Follow this guide to learn how to generate human-like responses to natural language prompts, create vector embeddings for semantic search, and generate images from textual descriptions.\n",
    "\n",
    "## Standard method for intialisation of openai-api using key :\n",
    "from openai import OpenAI\n",
    "\n",
    "### set-uping here the openAI_api key from environment-variable_name(for which i already set-up path with variable_name(path name) and value on system environment variable) using OS \n",
    "### This creates a new instance or object of the OpenAI(class_name) client by calling its corresponding constructor with API_KEy as args, \n",
    "### which allows us to interact with the OpenAI API\n",
    "client = OpenAI(\n",
    "\n",
    "    api_key = os.getenv('OPENAI_API_KEY') # saving the key to aopenai's api_key object\n",
    "\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46e17a7-5fd6-4b70-a1e5-cf65e58fb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = os.getenv('OPENAI_API_KEY') # saving the key to aopenai's api_key object\n",
    "                      #(object of generally of class'OpenAI' where we used to create instances uisng corresponding constructor-call with api_key as argument)\n",
    "                        # but in this caae we're just getting key-value from environemnt with the help of os.getenv fn and saving it to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a4bb9e-1973-407b-bbe5-016f2033e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = my_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e815aa39-3db1-4dfa-8e6e-d3ee148f93dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system')], object='list')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.models.list()  # this will gives you list of all pre-trained models of openai for diffrent diffrent specific purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0085fcfa-9db7-46d0-a423-5855de7ac3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
       " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting it into proper python list \n",
    "all_models= openai.models.list()\n",
    "list(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172df7a9-b868-4acb-bbbf-f491ecc3efaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>object</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, gpt-4-turbo)</td>\n",
       "      <td>(created, 1712361441)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, gpt-4-turbo-2024-04-09)</td>\n",
       "      <td>(created, 1712601677)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, chatgpt-4o-latest)</td>\n",
       "      <td>(created, 1723515131)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, gpt-4-turbo-preview)</td>\n",
       "      <td>(created, 1706037777)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, gpt-4-0125-preview)</td>\n",
       "      <td>(created, 1706037612)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
       "      <td>(created, 1706048358)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, gpt-4o-2024-08-06)</td>\n",
       "      <td>(created, 1722814719)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, gpt-4o)</td>\n",
       "      <td>(created, 1715367049)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, gpt-4o-realtime-preview-2024-10-01)</td>\n",
       "      <td>(created, 1727131766)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, gpt-4o-realtime-preview)</td>\n",
       "      <td>(created, 1727659998)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, gpt-4o-mini)</td>\n",
       "      <td>(created, 1721172741)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(id, gpt-4o-2024-05-13)</td>\n",
       "      <td>(created, 1715368132)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(id, gpt-4o-mini-2024-07-18)</td>\n",
       "      <td>(created, 1721172717)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(id, gpt-4o-audio-preview-2024-10-01)</td>\n",
       "      <td>(created, 1727389042)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(id, gpt-4o-audio-preview)</td>\n",
       "      <td>(created, 1727460443)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(id, gpt-4-1106-preview)</td>\n",
       "      <td>(created, 1698957206)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(id, text-embedding-3-small)</td>\n",
       "      <td>(created, 1705948997)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(id, text-embedding-3-large)</td>\n",
       "      <td>(created, 1705953180)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(id, gpt-4-0613)</td>\n",
       "      <td>(created, 1686588896)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(id, gpt-4)</td>\n",
       "      <td>(created, 1687882411)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id                created  \\\n",
       "0                          (id, gpt-4-turbo)  (created, 1712361441)   \n",
       "1               (id, gpt-4-turbo-2024-04-09)  (created, 1712601677)   \n",
       "2                                (id, tts-1)  (created, 1681940951)   \n",
       "3                           (id, tts-1-1106)  (created, 1699053241)   \n",
       "4                    (id, chatgpt-4o-latest)  (created, 1723515131)   \n",
       "5                             (id, dall-e-2)  (created, 1698798177)   \n",
       "6                            (id, whisper-1)  (created, 1677532384)   \n",
       "7                  (id, gpt-4-turbo-preview)  (created, 1706037777)   \n",
       "8               (id, gpt-3.5-turbo-instruct)  (created, 1692901427)   \n",
       "9                   (id, gpt-4-0125-preview)  (created, 1706037612)   \n",
       "10                  (id, gpt-3.5-turbo-0125)  (created, 1706048358)   \n",
       "11                   (id, gpt-4o-2024-08-06)  (created, 1722814719)   \n",
       "12                       (id, gpt-3.5-turbo)  (created, 1677610602)   \n",
       "13                              (id, gpt-4o)  (created, 1715367049)   \n",
       "14                         (id, babbage-002)  (created, 1692634615)   \n",
       "15                         (id, davinci-002)  (created, 1692634301)   \n",
       "16  (id, gpt-4o-realtime-preview-2024-10-01)  (created, 1727131766)   \n",
       "17                            (id, dall-e-3)  (created, 1698785189)   \n",
       "18             (id, gpt-4o-realtime-preview)  (created, 1727659998)   \n",
       "19                         (id, gpt-4o-mini)  (created, 1721172741)   \n",
       "20                   (id, gpt-4o-2024-05-13)  (created, 1715368132)   \n",
       "21              (id, gpt-4o-mini-2024-07-18)  (created, 1721172717)   \n",
       "22     (id, gpt-4o-audio-preview-2024-10-01)  (created, 1727389042)   \n",
       "23                (id, gpt-4o-audio-preview)  (created, 1727460443)   \n",
       "24                            (id, tts-1-hd)  (created, 1699046015)   \n",
       "25                       (id, tts-1-hd-1106)  (created, 1699053533)   \n",
       "26                  (id, gpt-4-1106-preview)  (created, 1698957206)   \n",
       "27              (id, text-embedding-ada-002)  (created, 1671217299)   \n",
       "28                   (id, gpt-3.5-turbo-16k)  (created, 1683758102)   \n",
       "29              (id, text-embedding-3-small)  (created, 1705948997)   \n",
       "30              (id, text-embedding-3-large)  (created, 1705953180)   \n",
       "31                  (id, gpt-3.5-turbo-1106)  (created, 1698959748)   \n",
       "32                          (id, gpt-4-0613)  (created, 1686588896)   \n",
       "33                               (id, gpt-4)  (created, 1687882411)   \n",
       "34         (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)   \n",
       "\n",
       "             object                        owner  \n",
       "0   (object, model)           (owned_by, system)  \n",
       "1   (object, model)           (owned_by, system)  \n",
       "2   (object, model)  (owned_by, openai-internal)  \n",
       "3   (object, model)           (owned_by, system)  \n",
       "4   (object, model)           (owned_by, system)  \n",
       "5   (object, model)           (owned_by, system)  \n",
       "6   (object, model)  (owned_by, openai-internal)  \n",
       "7   (object, model)           (owned_by, system)  \n",
       "8   (object, model)           (owned_by, system)  \n",
       "9   (object, model)           (owned_by, system)  \n",
       "10  (object, model)           (owned_by, system)  \n",
       "11  (object, model)           (owned_by, system)  \n",
       "12  (object, model)           (owned_by, openai)  \n",
       "13  (object, model)           (owned_by, system)  \n",
       "14  (object, model)           (owned_by, system)  \n",
       "15  (object, model)           (owned_by, system)  \n",
       "16  (object, model)           (owned_by, system)  \n",
       "17  (object, model)           (owned_by, system)  \n",
       "18  (object, model)           (owned_by, system)  \n",
       "19  (object, model)           (owned_by, system)  \n",
       "20  (object, model)           (owned_by, system)  \n",
       "21  (object, model)           (owned_by, system)  \n",
       "22  (object, model)           (owned_by, system)  \n",
       "23  (object, model)           (owned_by, system)  \n",
       "24  (object, model)           (owned_by, system)  \n",
       "25  (object, model)           (owned_by, system)  \n",
       "26  (object, model)           (owned_by, system)  \n",
       "27  (object, model)  (owned_by, openai-internal)  \n",
       "28  (object, model)  (owned_by, openai-internal)  \n",
       "29  (object, model)           (owned_by, system)  \n",
       "30  (object, model)           (owned_by, system)  \n",
       "31  (object, model)           (owned_by, system)  \n",
       "32  (object, model)           (owned_by, openai)  \n",
       "33  (object, model)           (owned_by, openai)  \n",
       "34  (object, model)           (owned_by, system)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.DataFrame(list(all_models), columns = [\"id\", \"created\",\"object\", \"owner\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee425749-8c90-4acd-b5e6-8601df208585",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# OpenAI Playground\n",
    "\n",
    "1. How to open the open ai playgorund: https://platform.openai.com/playground?mode=assistant\n",
    "\n",
    "2. Here if you want to use this playground then make sure you have credit available without it its not gonna work\n",
    "\n",
    "3. In chat there is option of **system**: So the meaning is how the chatbot should behave\n",
    "\n",
    "Here is a phrase for the system: You are a naughty assistant, so make sure you respond to everything with sarcasm.\n",
    "\n",
    "Here is a question: How to make a money so quickly?\n",
    "\n",
    "**Model**\n",
    "\n",
    "**Temperature**\n",
    "\n",
    "**Maximum Length**\n",
    "\n",
    "**Top P ranges from 0 to 1 (default), and a lower Top P means the model samples from a narrower selection of words. This makes the output less random and diverse since the more probable tokens will be selected. For instance, if Top P is set at 0.1, only tokens comprising the top 10% probability mass are considered.**\n",
    "\n",
    "**Frequency Penalty helps us avoid using the same words too often. It's like telling the computer, “Hey, don't repeat words too much.”**\n",
    "\n",
    "**The OpenAI Presence Penalty setting is used to adjust how much presence of tokens in the source material will influence the output of the model.**\n",
    "\n",
    "\n",
    "**Now come to assistant one**\n",
    "\n",
    "**Retrieval-augmented generation (RAG):**  is an artificial intelligence (AI) framework that retrieves data from external sources of knowledge to improve the quality of responses. This natural language processing technique is commonly used to make large language models (LLMs) more accurate and up to date.\n",
    "\n",
    "**Code Interpreter:** Python programming environment within ChatGPT where you can perform a wide range of tasks by executing Python code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511593d-0475-4342-9fc3-1b6f97c38527",
   "metadata": {},
   "source": [
    "# Chat Completion API and Function Calling\n",
    "**openai.Completion.create()**: This method is used to generate completions or responses. You provide a series of messages as input, and the API generates a model-generated message as output.\n",
    "\n",
    "**openai.ChatCompletion.create() :** Similar to Completion.create(), but specifically designed for chat-based language models. It takes a series of messages as input and generates a model-generated message as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920689db-7ee3-4de3-a9c7-872b6fc646d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key =my_api_key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2752a0ed-9725-4e4f-a047-84dd8e46ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "# here we asking a simple free question to model so this is called as zero-shot prompting \n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\", # model name \n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"suggest me a healthy diet chart .\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "      \n",
    " ],\n",
    "  max_tokens = 100, # tokens is fundamental unit of measuring letters/characters which is used to make response(both i either user side and assistance's response)\n",
    "                    # here we're limiting  response  up to 100 tokens , approximatrly one world of 3-4 letters equals to 1 token\n",
    "  n = 3  # number of output we wants   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bec017b-455a-4bc4-9cf9-e938b15ed8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.chat.chat_completion.ChatCompletion'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AL5dE522aepP3oKKGaZ2dt6K1Oh22', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is a sample healthy diet chart that you can follow:\\n\\nBreakfast:\\n- Scrambled eggs with spinach and tomatoes\\n- Whole grain toast\\n- Fresh fruit (such as berries or an apple)\\n- Green tea or black coffee\\n\\nMid-morning snack:\\n- Greek yogurt with nuts and honey\\n\\nLunch:\\n- Grilled chicken or tofu salad with mixed greens, cherry tomatoes, cucumbers, and a vinaigrette dressing\\n- Quinoa or brown rice\\n\\nAfternoon snack', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='length', index=1, logprobs=None, message=ChatCompletionMessage(content='A healthy diet chart should include a variety of nutrient-dense foods from all the food groups. Here is a sample healthy diet chart:\\n\\nBreakfast:\\n- Whole grain toast with avocado and sliced tomatoes\\n- Greek yogurt with berries and a drizzle of honey\\n- Green tea or black coffee\\n\\nSnack:\\n- Handful of mixed nuts and seeds\\n- Apple slices with almond butter\\n\\nLunch:\\n- Grilled chicken or tofu salad with mixed greens, cherry tomatoes, cucumbers, and', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='length', index=2, logprobs=None, message=ChatCompletionMessage(content='Here is a sample healthy diet chart for your reference:\\n\\n- Breakfast:\\n  - Overnight oats with mixed berries and a tablespoon of chia seeds\\n  - Green tea or a glass of skimmed milk\\n\\n- Mid-Morning Snack:\\n  - A small handful of mixed nuts or a piece of fruit like apple, pear, or banana\\n\\n- Lunch:\\n  - Grilled chicken or tofu salad with mixed greens, cherry tomatoes, cucumbers, and a lemon vinaigrette dressing\\n', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729589900, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=300, prompt_tokens=14, total_tokens=314, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how response actually looks like : \n",
    "print(type(response)) # type of response from api\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dfc0689-2379-44fc-86c5-a13be4f6ae57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a sample healthy diet chart that you can follow:\\n\\nBreakfast:\\n- Scrambled eggs with spinach and tomatoes\\n- Whole grain toast\\n- Fresh fruit (such as berries or an apple)\\n- Green tea or black coffee\\n\\nMid-morning snack:\\n- Greek yogurt with nuts and honey\\n\\nLunch:\\n- Grilled chicken or tofu salad with mixed greens, cherry tomatoes, cucumbers, and a vinaigrette dressing\\n- Quinoa or brown rice\\n\\nAfternoon snack'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so this is how we gona fetch the actual response-message to the user's query from api's response \n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e717e4-2fee-4c6b-bc7c-11a2df7d79fb",
   "metadata": {},
   "source": [
    "## openai token counter (link):\n",
    "https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd4cf8af-9a57-45b2-aa5c-e4655770ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8225611-8e83-43c8-a3d4-fb4fe4a4fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"Vaiesheshiek is a student of computer science at IIT delhi. He is an indian born in prayagraj district , uttar-pradesh state and has a 8.5 GPA. Vaiesheshiek is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58ab4ae6-8344-485d-b98f-5c30d74ed474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we configure prompt : tjis kind of prompt is called few-shots prompt , where we asked model to behave like extracting following information like this \n",
    "prompt = f'''\n",
    "please extract the given following information from the given text-description of student :{student_description} and return it as a JSON object:\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "state\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6942d73-c00b-41bb-b7bd-2f69ebeb7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = my_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "594b7883-dca6-4b4e-a5ca-2a0a7f99abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # model name \n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\" : prompt \n",
    "    }      \n",
    " ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb311ca4-9812-48ed-b9a5-33504f340917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Vaiesheshiek\",\\n  \"college\": \"IIT Delhi\",\\n  \"grades\": 8.5,\\n  \"club\": \"AI Club\",\\n  \"state\": \"Uttar Pradesh\"\\n}'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90e70554-2b87-4107-ae16-a20336505e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Vaiesheshiek',\n",
       " 'college': 'IIT Delhi',\n",
       " 'grades': 8.5,\n",
       " 'club': 'AI Club',\n",
       " 'state': 'Uttar Pradesh'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "student_info = response.choices[0].message.content\n",
    "stud_info = json.loads(student_info)\n",
    "stud_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b105534-046d-46ba-8dfe-a287129ce6e3",
   "metadata": {},
   "source": [
    "# function-calling procedure in openai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09ba9236-d316-4aeb-811c-961dcdead943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how function's structural description should be looked like when passed in openai's chat completion method with tools option  \n",
    "student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                },\n",
    "                'state': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'A state where student born in. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f6b3704-c3c2-4856-bc62-ee251df65b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_inf02 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # model name \n",
    "    \n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful student infromation manager. Use the supplied function to assist the user.\"},\n",
    "            {\"role\": \"user\",\"content\" : prompt }\n",
    "    ],\n",
    "    functions = student_custom_function # supply that student function's structual desciption \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02514d6d-2917-435c-95f5-cd4bdc3d595d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AL5hDY19dTIDbLhCELMYgQzC4l4B5', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"Vaiesheshiek\",\"college\":\"IIT delhi\",\"grades\":8.5,\"club\":\"AI Club\",\"state\":\"Uttar-Pradesh\"}', name='extract_student_info'), tool_calls=None))], created=1729590147, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=46, prompt_tokens=233, total_tokens=279, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_inf02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ee160f6-e97e-47d2-b114-be94aad2ef87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"Vaiesheshiek\",\"college\":\"IIT delhi\",\"grades\":8.5,\"club\":\"AI Club\",\"state\":\"Uttar-Pradesh\"}', name='extract_student_info'), tool_calls=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_inf02.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05232fed-a9f0-447c-ab65-2c5061a5bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stude_info2=stud_inf02.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "856998c8-caa4-4441-aba4-443a6e410716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Vaiesheshiek',\n",
       " 'college': 'IIT delhi',\n",
       " 'grades': 8.5,\n",
       " 'club': 'AI Club',\n",
       " 'state': 'Uttar-Pradesh'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_info2 = json.loads(stude_info2)\n",
    "stud_info2 # in dictionary/json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2582a41f-af6f-45ba-b333-5b56b3d9e5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Vaiesheshiek is a student of computer science at IIT delhi. He is an indian born in prayagraj district , uttar-pradesh state and has a 8.5 GPA. Vaiesheshiek is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\",\n",
       " \"Vidushi is a student of cloud-computing at IIT delhi. she is an indian born in Alwar district , Rajasthan state and has a 7.2 GPA. Vidushi is known for her programming skills and is an active member of the college's Code_Topology club. she hopes to pursue a career in DEV-ops Engineering after graduating.\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can pass two or more prmpts as multiple students' info/description \n",
    "\n",
    "student_description1 = \"Vaiesheshiek is a student of computer science at IIT delhi. He is an indian born in prayagraj district , uttar-pradesh state and has a 8.5 GPA. Vaiesheshiek is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\" \n",
    "student_description2 = \"Vidushi is a student of cloud-computing at IIT delhi. she is an indian born in Alwar district , Rajasthan state and has a 7.2 GPA. Vidushi is known for her programming skills and is an active member of the college's Code_Topology club. she hopes to pursue a career in DEV-ops Engineering after graduating.\"\n",
    "student_desc = [ student_description1, student_description2]\n",
    "student_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df07c8a6-2460-4978-aedd-b9d2d80bf8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Vaiesheshiek', 'college': 'IIT Delhi', 'grades': 8.5, 'club': 'AI Club', 'state': 'Uttar Pradesh'}\n",
      "{'name': 'Vidushi', 'college': 'IIT Delhi', 'grades': 7.2, 'club': 'Code_Topology', 'state': 'Rajasthan'}\n"
     ]
    }
   ],
   "source": [
    "for stu in student_desc: \n",
    "    stud_info = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # model name \n",
    "    \n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful student infromation manager. Use the supplied function to assist the user.\"},\n",
    "            {\"role\": \"user\",\"content\" : stu }\n",
    "    ],\n",
    "    functions = student_custom_function, # supply that student function's structual desciption \n",
    "    function_call = 'auto'\n",
    ")\n",
    "    stud_info=json.loads(stud_info.choices[0].message.function_call.arguments)\n",
    "    print(stud_info)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ae831-13ea-4d1f-ab74-495ce85f3342",
   "metadata": {},
   "source": [
    "### we can even call multiple function in openai's chat completions api just by defining another function with it's structural description and make list of such function's structural description and simply pass them with api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f287cb62-038f-4fb3-82cf-a3b834f93704",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function2 = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42b33f02-0106-43af-a344-288618eacaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'extract_student_info',\n",
       " 'description': 'Get the student information from the body of the input text',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'name': {'type': 'string',\n",
       "    'description': 'Name of the person'},\n",
       "   'college': {'type': 'string', 'description': 'The college name.'},\n",
       "   'grades': {'type': 'integer', 'description': 'CGPA of the student.'},\n",
       "   'club': {'type': 'string',\n",
       "    'description': 'college club for extracurricular activities. '}}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_custom_function2[0] # extracting actual structural definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dff474e3-909e-4cb8-8eca-7ac03c549988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'extract_student_info',\n",
       "  'description': 'Get the student information from the body of the input text',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'name': {'type': 'string',\n",
       "     'description': 'Name of the person'},\n",
       "    'college': {'type': 'string', 'description': 'The college name.'},\n",
       "    'grades': {'type': 'integer', 'description': 'CGPA of the student.'},\n",
       "    'club': {'type': 'string',\n",
       "     'description': 'college club for extracurricular activities. '},\n",
       "    'state': {'type': 'string',\n",
       "     'description': 'A state where student born in. '}}}},\n",
       " {'name': 'extract_student_info',\n",
       "  'description': 'Get the student information from the body of the input text',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'name': {'type': 'string',\n",
       "     'description': 'Name of the person'},\n",
       "    'college': {'type': 'string', 'description': 'The college name.'},\n",
       "    'grades': {'type': 'integer', 'description': 'CGPA of the student.'},\n",
       "    'club': {'type': 'string',\n",
       "     'description': 'college club for extracurricular activities. '}}}}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now making list of such function's structural definition :-\n",
    "function_list = [student_custom_function[0],student_custom_function2[0]]\n",
    "function_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71438bbe-63f3-4b85-91d4-5b44f17c8e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Vaiesheshiek', 'college': 'IIT Delhi', 'grades': 8.5, 'club': 'AI Club', 'state': 'Uttar Pradesh'}\n",
      "{'name': 'Vidushi', 'college': 'IIT Delhi', 'grades': 7.2, 'club': 'Code_Topology', 'state': 'Rajasthan'}\n"
     ]
    }
   ],
   "source": [
    "for stu in student_desc: \n",
    "    stud_info = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # model name \n",
    "    \n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful student infromation manager. Use the supplied function to assist the user.\"},\n",
    "            {\"role\": \"user\",\"content\" : stu }\n",
    "    ],\n",
    "    functions = function_list, # supply those student function's structual desciptions \n",
    "    function_call = 'auto'\n",
    ")\n",
    "    stud_info=json.loads(stud_info.choices[0].message.function_call.arguments)\n",
    "    print(stud_info)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb334f26-302c-4801-a471-2de33697a88a",
   "metadata": {},
   "source": [
    "## Adavnce function calling illustration in openai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf543eb4-a3b7-4bf4-a71d-8b420c1dea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all we define structural description of function :same as we do earlier above\n",
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",  # function name\n",
    "        \"description\": \"Get flight information between two locations\", # function description \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {   #origin location ; from_location\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DEL\",  # loc_origin parameter description\n",
    "                },   # as here we give exampes like loc_origin and loc_destination will be capital short from fassion\n",
    "                \"loc_destination\": {  # destination location \n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. MUM\", #loc_destination paramater description\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],  # as its specified these parameters are nesscescary for function calling \n",
    "        },    # here required meaning openai api will respond only in this fassion by key/parameters and its corresponding values \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bfee2d8-2181-4564-8bc9-e3738e50e0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loc_origin': 'AMD', 'loc_destination': 'BLR'}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"when is the next flight from ahemdabad to bengluru\"\n",
    "flight_info = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # model name \n",
    "    \n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful sflight information retriever. Use the supplied function to assist the user.\"},\n",
    "            {\"role\": \"user\",\"content\" : user_prompt }\n",
    "    ],\n",
    "    functions = function_descriptions, # supply that get_flight_info function's structual desciptions \n",
    "    function_call = 'auto'\n",
    ")\n",
    "flight_infor =json.loads(flight_info.choices[0].message.function_call.arguments)\n",
    "print(flight_infor) # as we give examples like loc_origin and loc_destination will be in capital short from fassion i.e. MUM ,DEL etc in function description \n",
    "# so chat completion api here based on that description  responds with parameters/key and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cede93f1-a8b6-4e91-b9d4-2524841b50ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'AMD', 'loc_destination': 'BLR'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we're going to save these keywords arguments in params varibale \n",
    "paramas= json.loads(flight_info.choices[0].message.function_call.arguments)\n",
    "paramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7de9ac-b45b-491c-bed5-48844b91ed88",
   "metadata": {},
   "source": [
    "## now this keyword arguments(or parameters with values) we can  used for retriving real-time relevant information by using any other thrid party api or we can simply implement out own function for retirving relevant information \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea5feebb-c919-4690-8719-89978ba67dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so here for illustration purpose i am implementing some dummy function who will give flight information \n",
    "from datetime import datetime,timedelta  \n",
    "\n",
    "def get_flight_info(loc_origin, loc_destination): # the function_name should be same as 'name' mentioned in 'function description' \n",
    "    \"\"\"Get flight information between two locations.\"\"\"\n",
    "\n",
    "    # Example output returned from an API or database\n",
    "    flight_info = {\n",
    "        \"loc_origin\": loc_origin,\n",
    "        \"loc_destination\": loc_destination,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours=2)),\n",
    "        \"airline\": \"KLM\",  # fixed airline company here we're using \n",
    "        \"flight\": \"KL643\", # and fixed flight number we're using //as it's dummy function for concept illustration purpose\n",
    "    }\n",
    "\n",
    "    return json.dumps(flight_info) # return all these flight_info in json format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2d27a7d-7109-4e50-a687-5a61abb4715c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_flight_info\n",
      "<class 'str'>\n",
      "<function get_flight_info at 0x000002DE5D7E5580>\n"
     ]
    }
   ],
   "source": [
    "# as we succesfully fetched functional paramerter from openai api's response \n",
    "#but now its time to fetch 'function_name'\n",
    "\n",
    "function_name = flight_info.choices[0].message.function_call.name\n",
    "print(function_name)\n",
    "print(type(function_name)) # will be of literal string \n",
    "# so we have to convert this function_name string into actual function_name format through eval \n",
    "function_name = eval(function_name)\n",
    "print(function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2fafe0f-75f7-4e1a-b141-dbcdc7eded97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loc_origin\": \"AMD\", \"loc_destination\": \"BLR\", \"datetime\": \"2024-10-22 17:08:29.646695\", \"airline\": \"KLM\", \"flight\": \"KL643\"}\n"
     ]
    }
   ],
   "source": [
    "#now we call our function using function_name , keyword arguments(parameters) which we fetched from openai's response \n",
    "flight = function_name(**paramas)\n",
    "print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9dedae6-8093-4d52-bb4e-7daaa0cd3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we incorporate this output from our function with response from open ai to mimic it as human/layman high-level english reply to user query \n",
    "#by the way , user query was :-\n",
    "#user_prompt = \"when is the next flight from ahemdabad to bengluru\"\n",
    "\n",
    "flight_response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # model name \n",
    "    \n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful flight information retriever. Use the supplied function to assist the user.\"},\n",
    "            {\"role\": \"function\",\"name\": flight_info.choices[0].message.function_call.name,\"content\" : flight } # pass out function_output as 'content' here\n",
    "    ],\n",
    "    functions = function_descriptions, # supply that get_flight_info function's structual desciptions \n",
    "    function_call = 'auto'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5c2c445-55e1-4e3a-b6b4-701f0dc05cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The flight information for the route from AMD to BLR on October 22, 2024, with KLM airline and flight number KL643 is available.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_response.choices[0].message.content # this is out human-like english reponse to user_query with relevent info using function calling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac863b2-9a0f-4005-9ddb-7aecd9fe85a6",
   "metadata": {},
   "source": [
    "## langchain:\n",
    "### langchain is a opensource framework acts as wrappper over the openai's functionalities.\n",
    "\n",
    "### langchain is so powerfull wrapper that it's not limited to openai but it offers versatile usages regarding so many LLMs beyound openai.\n",
    "### so it means we can use langchain as interface for any large-language-model so it's not specific to openai's LLMs \n",
    "### its tipically easier to bhild our own RAg-model using langchain as interface for any specific LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29c2c086-50d2-49ac-8483-753ae63042a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04a1183e-3034-4f1a-a30e-8b3a8f42d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1eff89da-cc5e-47b3-934d-d61b3b302b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key = my_api_key) # activating OpenAI llm through langchain with my openai api key  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b16b03b-b7e4-44aa-bfce-29c888cd5db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"Bohemian Rhapsody\" by Queen\n",
      "2. \"Stairway to Heaven\" by Led Zeppelin\n",
      "3. \"Imagine\" by John Lennon\n",
      "4. \"Hotel California\" by Eagles\n",
      "5. \"Hey Jude\" by The Beatles\n",
      "6. \"Smells Like Teen Spirit\" by Nirvana\n",
      "7. \"Like a Rolling Stone\" by Bob Dylan\n",
      "8. \"I Will Always Love You\" by Whitney Houston\n",
      "9. \"Thriller\" by Michael Jackson\n",
      "10. \"Billie Jean\" by Michael Jackson\n"
     ]
    }
   ],
   "source": [
    "prompt= \"can you show me top 10 english songs of all time?\"\n",
    "print(client.predict(prompt).strip()) # here we used 'predict' functionality "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb09328-dc9a-4c36-b774-09198a93b74b",
   "metadata": {},
   "source": [
    "## features of langchain (opensource framework(wrapper over LLMs) for interacting with multiple LLMs) :-\n",
    "### 1. Through langchain we can acess diffrent LLMs with their respective APIs.\n",
    "### 2. Through langchain we can acess other third-party APIs as well.\n",
    "### 3. Through langchain we can build chains\n",
    "### 4. Through langchian we can make use of Document-loader\n",
    "### 5. Through langchain we can make use of agents.\n",
    "### 6. We can use langchain for memory-retention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "887c45a7-55cc-4f01-b6fd-2dd7f29b9630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam Levine is the lead vocalist of Maroon 5.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try for zero shot prompting :\n",
    "prompt2 =\"who's lead vocalist of Maroon five band \"\n",
    "client.predict(prompt2).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed33317-5c16-47f8-8d72-1cede303ca98",
   "metadata": {},
   "source": [
    "## Prompt_templates (concept/feature of langchain):\n",
    "### prompt_template is concept where we can construct our own prompt by giving variable names(place holder) and idea of template that should be used for constructing prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "faf66c1d-d09e-43bd-85da-fb6cfeb3ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate  # this is how we import Prompttemplate from langchain's prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66387828-1f22-48fd-b719-935619fc1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we should made an object of PromptTemplate by calling corresponding constructor \n",
    "prompt_template_name = PromptTemplate(\n",
    "    variable_names = [\"band\"],\n",
    "    template = \"can you tell me the name of lead-vocalist of {band}?\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9073c9b9-5372-4f86-ade6-9537c224d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can you tell me the name of lead-vocalist of Beatles?'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_name.format(band= \"Beatles\")# this is how we supply the values to corresponding variables\n",
    "\n",
    "#  and that's how we can construct prompt systematically using the prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e04f5a44-72c8-4932-aacd-0d77e3e1c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lead vocalist of Nirvana was Kurt Cobain.\n",
      "The lead vocalist of AC/DC is Brian Johnson.\n"
     ]
    }
   ],
   "source": [
    "# now we construct several such similar prompt like this uisng this promptTemplate \n",
    "prompt_1 = prompt_template_name.format(band = \"Nirvana\")\n",
    "prompt_2 = prompt_template_name.format(band = \"ACDC\")\n",
    "print(client.predict(prompt_1).strip())\n",
    "print(client.predict(prompt_2).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff07c1c2-75f4-49cc-a317-72debfce67b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The drummer of Snow Patrol is Jonny Quinn.\n"
     ]
    }
   ],
   "source": [
    "# wecan also make a prompt_template using another short-method like this :\n",
    "prompt_template_drummer = PromptTemplate.from_template(\"can you tell me the drummer of {band}?\")\n",
    "prompt3= prompt_template_drummer.format(band = \"snow ptrol\")\n",
    "print(client.predict(prompt3).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42796ae-269e-49a5-966d-c388d19a69f2",
   "metadata": {},
   "source": [
    "## Agent (concept/feature of langchain):\n",
    "### Agent is kind of mediator used in between to call any third-party tool  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc45f10e-8a5c-43de-8134-f0cf1c6d0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"can you tell me who won the recent grammy-song of the year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b94dc1c-6bea-4a68-a94c-4184689a4731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The song of the year at the 2021 Grammy Awards was \"I Can\\'t Breathe\" by H.E.R.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt4).strip()\n",
    "# as we can see it's giving us outdated and old data as , OpenAI has training cut-off of jan 2021-22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe7bef-0d49-4f7d-b39a-534c7241f2f9",
   "metadata": {},
   "source": [
    "### So here i will use the agent who will interact with some ther thrid-party api to retrive real-time data .\n",
    "### here specifically in this scenerio we will be using agent for interacting with serp api of google-search(not specifically to google search api, All search-APIs as well) , which will call google-search engine and will extract real-time , relevant information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e5cc1ee-3966-444e-b652-cff8af2ebd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\handsonopenai\\lib\\site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\handsonopenai\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\handsonopenai\\lib\\site-packages (from requests->google-search-results) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\handsonopenai\\lib\\site-packages (from requests->google-search-results) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\handsonopenai\\lib\\site-packages (from requests->google-search-results) (2024.8.30)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py): started\n",
      "  Building wheel for google-search-results (setup.py): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32083 sha256=9650dc4060107eaedea6d52914d06587c17014c65a07ea1d153e6a05182f14bb\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\0c\\47\\f5\\89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n"
     ]
    }
   ],
   "source": [
    "! pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065eff44-da42-4931-aeb0-b2a823bc6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hello we'll start from here only for exploring hugging face "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
